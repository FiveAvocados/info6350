Number;Speaker;Start time;End time;Duration;Text
0;Speaker 1;00:01:37.190;00:01:37.740;00:00:00.550;"Hello?"
1;Speaker 2;00:01:39.810;00:01:53.380;00:00:13.570;"Sorry, I have the sound off. I still don't hear you, but it might be on my end. Let me check."
2;Speaker 1;00:02:13.790;00:02:15.530;00:00:01.740;"Hi, Maryanne. Do you hear me now?"
3;Speaker 2;00:02:15.630;00:02:17.330;00:00:01.700;"Hi. Yeah, I can hear you now."
4;Speaker 1;00:02:17.490;00:02:34.300;00:00:16.810;"Great. Okay. Thank you for participating the interview. I really appreciate it. Oh, yeah. Should we get started? First of all, can you do this?"
5;Speaker 2;00:02:34.990;00:02:35.460;00:00:00.470;"Okay."
6;Speaker 1;00:02:35.540;00:02:39.650;00:00:04.110;"So do you mind if I record this pilot interview?"
7;Speaker 2;00:02:40.450;00:02:42.640;00:00:02.190;"I think it's already recording, but yes."
8;Speaker 1;00:02:44.350;00:02:56.090;00:00:11.740;"Thank you. And can you do this survey quickly before I ask interpret questions? I will share it on the chat."
9;Speaker 2;00:02:56.590;00:02:57.340;00:00:00.750;"Okay."
10;Speaker 1;00:03:00.890;00:03:06.080;00:00:05.190;"And let me know if you have any questions with the survey. Questions?"
11;Speaker 2;00:03:07.790;00:03:09.270;00:00:01.480;"Yeah. It's just setting."
12;Speaker 1;00:03:09.890;00:03:10.640;00:00:00.750;"Sure."
13;Speaker 2;00:03:26.550;00:03:41.090;00:00:14.540;"Okay. Because, I mean, I really just did the internship. Just say one year."
14;Speaker 1;00:03:41.260;00:03:41.980;00:00:00.720;"Yeah."
15;Speaker 2;00:03:43.210;00:04:05.690;00:00:22.480;"Okay. I'm not sure if counts as a big or mid sized firm. I guess it's about 750 employees."
16;Speaker 1;00:04:07.690;00:04:10.300;00:00:02.610;"I think maybe mid site firm."
17;Speaker 2;00:04:10.450;00:04:45.320;00:00:34.870;"Okay. For collaborations that you collaborate with, this is, I guess, more feedback than anything else. But I would include project managers there as well, which are different than project managers. Right."
18;Speaker 1;00:04:47.390;00:04:48.270;00:00:00.880;"Pardon?"
19;Speaker 2;00:04:49.850;00:04:57.090;00:00:07.240;"In industry, especially in tech industry, you have here UI designers, developers and project managers."
20;Speaker 1;00:04:57.200;00:04:57.860;00:00:00.660;"Yes."
21;Speaker 2;00:04:58.550;00:05:06.380;00:00:07.830;"And in industry, you do work with project managers? Sometimes, but you'll also work with product managers. Thank you."
22;Speaker 1;00:05:12.050;00:05:16.590;00:00:04.540;"What are the differences between project manager and product manager?"
23;Speaker 2;00:05:18.110;00:05:24.140;00:00:06.030;"Project manager. They're actually a little less common in terms of developing tech products."
24;No speaker;00:05:26.370;00:05:30.600;00:00:04.230;"So product managers often are the person that is in charge of the feature."
25;Speaker 2;00:05:30.690;00:05:59.200;00:00:28.510;"So they're, like, deciding what gets built. And they're often. So the reason UI and product often is where they overlap, at least in my old role, I used to be a product manager. That's why I know about it. But in my old role as a product manager, I would be the person that engages with the UX researchers. So I would say, we need research. You can lump them together if you want. You can do project products managers, but that's it."
26;Speaker 1;00:06:01.210;00:06:01.660;00:00:00.450;"I see."
27;Speaker 2;00:06:01.680;00:06:13.820;00:00:12.140;"And then there's also, like, marketing could be relevant for UX research. And then I don't know if you want to do something like developers. Does that also include data science, for example?"
28;Speaker 1;00:06:14.270;00:06:15.020;00:00:00.750;"Right."
29;Speaker 2;00:06:16.670;00:06:21.630;00:00:04.960;"I'm trying to think. I feel like those are the biggest categories."
30;Speaker 1;00:06:22.550;00:06:24.350;00:00:01.800;"Thank you for the feedback."
31;Speaker 2;00:06:24.540;00:07:05.630;00:00:41.090;"So there's what's the size of your team? And then there's how many others do you collaborate with, but only onto people in your team, which can be a little confusing because, for example, organizations will put UX researchers all in a team together and others will be in like a product team. So you might work with other UX researchers, but they're not going to be in your team."
32;Speaker 1;00:07:05.810;00:07:09.730;00:00:03.920;"That's true. Yeah. I should open this to their dad."
33;Speaker 2;00:07:13.690;00:07:15.410;00:00:01.720;"Sorry. There's a sirenville."
34;Speaker 1;00:07:15.460;00:07:16.730;00:00:01.270;"No worries."
35;Speaker 2;00:07:37.730;00:07:55.940;00:00:18.210;"I think another thing I would say, it says, what was the percentage you spent on conducting qualitative data analysis? So would that be just for the analysis part after you've collected the data, or does it include interview time, for example?"
36;Speaker 1;00:07:56.510;00:07:58.850;00:00:02.340;"I think includes interview time."
37;Speaker 2;00:07:59.010;00:07:59.720;00:00:00.710;"Okay."
38;Speaker 1;00:08:00.110;00:08:02.090;00:00:01.980;"Maybe I should specify that."
39;Speaker 2;00:08:02.250;00:08:26.030;00:00:23.780;"Yeah, I think this is fine as a question. I'm just thinking that usually goes in like. Well, I guess it depends. In my experience, it usually waves. So sometimes you're doing a lot of that, and then other times you're doing different things, basically. So it can be as a percentage because it's not the same."
40;Speaker 1;00:08:26.130;00:08:26.670;00:00:00.540;"I see."
41;Speaker 2;00:08:26.720;00:09:43.870;00:01:17.150;"But I mean, I can, like mentally average over everything and say for what I think. I also think this one's going to be difficult to answer. How fast is the project cycle is super dependent? Right. On, like, is it a feature? Is it a product? Is it a big feature? Is it like big or small? Right. So some companies have like, two week cycles, for example, that they work in. But that doesn't mean that like a project that you as a UX research are working on is going to take two weeks. So this one is actually super difficult to answer. I would say."
42;Speaker 1;00:09:43.970;00:10:09.080;00:00:25.110;"I see. Right. So I wanted to ask, even though they don't participate, the whole project, as a US researchers, I kind of wanted to see how long does it take to develop if it's one feature or can you just answer it after you average them out?"
43;Speaker 2;00:10:11.030;00:10:14.670;00:00:03.640;"Well, it depends because it depends on if it's something big or something small. Right."
44;Speaker 1;00:10:14.780;00:10:15.560;00:00:00.780;"I see."
45;Speaker 2;00:10:15.700;00:10:24.340;00:00:08.640;"Launching a new product is going to take two years. A new feature is going to take two months."
46;Speaker 1;00:10:24.540;00:10:29.540;00:00:05.000;"I see. Maybe I should ask more specific questions."
47;Speaker 2;00:10:31.250;00:10:33.260;00:00:02.010;"This one in particular, actually, I think."
48;Speaker 1;00:10:33.340;00:12:11.940;00:01:38.600;"Yeah. Thank you. Next, I'm going to share a link to a Figma, and up there you're going to make a very simple diagram, and there's an instruction on Sigma. I'll explain it in detail after I share the link. Can you access it?"
49;Speaker 2;00:12:13.050;00:12:14.400;00:00:01.350;"Yes, I see it."
50;Speaker 1;00:12:14.540;00:14:01.510;00:01:46.970;"Okay. So what we want to do here is think about the process of your team when you are developing a product. As you mentioned, it can be like a two year project or you're just developing a feature. But would there be a very general process that you guys follow to develop a product? So I provided, like, simple elements that you can use and also provided an example that you can follow. But you don't have to follow the exact same example and feel free to be creative. And if I explain more about this example, it starts from the beginning when researchers idea what kind of product they should develop, and then during the whole process, they make certain decisions. And then please indicate where qualitative research is used during this whole process. And then it'll be great if you can specify the early and mid and end phase of the product development process. And also you can use these little icons like UX researchers, UI designers, developers, and such to indicate who are involved in those process and also use the red flag icon to indicate there are some challenges and conflicts during this whole process. Does it make sense?"
51;Speaker 1;00:14:01.570;00:14:04.460;00:00:02.890;"Or if you have any questions, just ask me."
52;Speaker 2;00:14:04.600;00:14:23.640;00:00:19.040;"It does make sense. So the primary research that I did actually was not linked to a product launch, so I can give it a go, but it's not necessarily going to like the end result is not necessarily a product, right?"
53;Speaker 1;00:14:23.720;00:14:34.480;00:00:10.760;"Yeah. Okay, then can you tell me if it's not related to the product, then what kind of project were you working on?"
54;Speaker 2;00:14:34.810;00:15:24.440;00:00:49.630;"Yeah, it was a user segmentation project, so it was from iPad. Basically, the higher ups wanted a better understanding of who the users were and how they're using the product and what types of archetypes they pull under. And so my job was to use qualitative and quantitative methods to define the primary user groups and types of users. The outcome was like the segmentation and the profiling and then presenting that and making materials so that they can be identified from the data and from talking to people. But it wasn't a thing that would have directed that to product."
55;Speaker 1;00:15:24.640;00:15:25.400;00:00:00.760;"I see."
56;Speaker 2;00:15:25.540;00:15:45.210;00:00:19.670;"That makes sense. Yeah. The other alternative. I mean, I used to work at Microsoft and I was not a UX researcher, but I worked with UX researchers. I think more in the way that you're describing of integrating them into launch process. So I can talk about that if you want, but I was not a UX reset share at that point."
57;Speaker 1;00:15:45.370;00:16:02.410;00:00:17.040;"I see. Okay, can you then make a diagram based on your experience at Microsoft and then also talk about your research experience, like segmenting users later after you finish the diagram?"
58;Speaker 2;00:16:03.930;00:16:13.020;00:00:09.090;"Yeah, I can try that. Okay. I also have not really used Sigma before, so I'm just going to. Okay. Do I need to log in?"
59;Speaker 1;00:16:14.910;00:16:17.940;00:00:03.030;"I don't think so. Does it ask you to log in?"
60;Speaker 2;00:16:21.250;00:16:26.260;00:00:05.010;"I don't. I can see it, but I don't think I can do anything until."
61;Speaker 1;00:16:27.130;00:16:52.950;00:00:25.820;"Okay, give me a second. Can you send me your email? Then I will send an invitation via your email. Then it will."
62;Speaker 2;00:16:53.050;00:16:57.840;00:00:04.790;"I think I can log in. There's a button that I can do to log in if I need to."
63;Speaker 1;00:16:57.920;00:16:58.570;00:00:00.650;"Okay."
64;Speaker 2;00:16:58.740;00:17:06.890;00:00:08.150;"But I don't know if I like. I guess I prefer not to create a user account if I don't have to. Okay."
65;Speaker 1;00:17:06.950;00:17:57.830;00:00:50.880;"If so, I'll just send the invitation to your email. Can you let me know your Cornell email, actually, sorry. I will send it again. Okay. I just sent it. Maybe you can."
66;Speaker 2;00:17:57.890;00:18:01.320;00:00:03.430;"Yeah, it's the same thing. So I think I need to just create an account."
67;Speaker 1;00:18:02.490;00:18:05.520;00:00:03.030;"No. Should I have thought about it before?"
68;Speaker 2;00:18:05.850;00:19:00.180;00:00:54.330;"I didn't know. Okay. Where did you want me to do this?"
69;Speaker 1;00:19:01.530;00:19:03.240;00:00:01.710;"Under the working space."
70;Speaker 2;00:19:21.970;00:20:56.080;00:01:34.110;"Okay, so we said this is the Microsoft process I guess. I don't know as much. What are the pain points in the Microsoft process, but I can. Should I copy all this stuff down here?"
71;Speaker 1;00:20:56.770;00:21:02.200;00:00:05.430;"Yeah, you can use that and also you can modify it if you need it."
72;Speaker 2;00:21:07.730;00:21:58.280;00:00:50.550;"Okay. What should I do for like different like the next step would be work with designer on products, for example."
73;Speaker 1;00:22:03.390;00:22:12.430;00:00:09.040;"That's a good question. Maybe you can make a new shape and just work with UI, like Designer."
74;Speaker 2;00:26:43.370;00:27:11.890;00:00:28.520;"And then it's a little hard to say with the red flags, to be honest, because I feel like shoes can curl up at many stages of the process. I would say each of these has its own pain points."
75;Speaker 1;00:27:12.000;00:27:17.660;00:00:05.660;"Oh, yeah, that's true. It's pain points from UX researchers point of view."
76;Speaker 2;00:27:17.860;00:27:25.010;00:00:07.150;"Yeah. I mean, again, like in this process, the UX researcher is really only involved in this, right?"
77;Speaker 1;00:27:25.130;00:27:26.030;00:00:00.900;"I see."
78;Speaker 2;00:27:26.210;00:27:34.680;00:00:08.470;"The whole rest is like the whole product ecosystem and the US feature would only be in this small piece."
79;Speaker 1;00:27:35.070;00:27:35.940;00:00:00.870;"I see."
80;Speaker 2;00:27:36.570;00:27:39.660;00:00:03.090;"This is maybe one representation of it."
81;Speaker 1;00:27:40.050;00:27:50.810;00:00:10.760;"I see. I came up with some questions based on your diagram. First of all, what is KPIs?"
82;Speaker 2;00:27:52.270;00:27:55.690;00:00:03.420;"Kpis is a key product insight."
83;Speaker 1;00:27:55.760;00:27:56.740;00:00:00.980;"I want to say."
84;Speaker 2;00:28:02.390;00:28:21.970;00:00:19.580;"It'S an industry time that is used for key performance indicators. There we go. It's basically set these at the beginning of the project. So you say, like, for example, with this feature, we're aiming to get 30% more conversions from sign up or something."
85;Speaker 1;00:28:22.090;00:28:22.700;00:00:00.610;"I see."
86;Speaker 2;00:28:22.780;00:28:46.100;00:00:23.320;"So after you launch, instead of doing more qualitative research, you wouldn't really do qualitative research after you launch because you've already launched. So you're front Loading the qualitative research to make sure you're not launching a bad product. Right. If you have to do quality research afterwards, I mean, you can do surveys or something, that's fine. But you wouldn't really be doing indepth user interviews because you already did those beforehand."
87;Speaker 1;00:28:46.250;00:28:47.120;00:00:00.870;"I see."
88;Speaker 2;00:28:47.930;00:28:55.050;00:00:07.120;"So you evaluate mostly based on these business matrix, the key product indicator. Key performance indicator."
89;Speaker 1;00:28:55.160;00:29:13.760;00:00:18.600;"I see. Then if you don't get the number that you expected from that keep performance indicator, then do you guys conduct another qualitative data analysis or user study to understand more deeply about the product or."
90;Speaker 2;00:29:15.470;00:29:54.660;00:00:39.190;"It depends on usually it's not always extremely black and white, like you might say between 10% to 30%, and then you track where it lands in there. If there are still pain points, you would continue to evaluate and maybe launch a new feature. But this whole thing takes a long time, right. And takes a lot of resources and a lot of time. So usually you're pretty sure at the time of launch that it's going to make a good difference. Like if it gets through this whole thing, there's a lot of decisions that are being made here and a lot of money that's being spent. So if it gets through this whole thing, usually."
91;Speaker 1;00:29:54.740;00:30:18.640;00:00:23.900;"I see. Thank you. And another question. Is why researchers are not involved in an early stage. According to this diagram, UI designers come up with designs first and then conduct qualitative research afterwards. Is there a reason why?"
92;Speaker 2;00:30:19.030;00:31:21.370;00:01:02.340;"Yeah, because qualitative research is really expensive in terms of time that it takes and in terms of how much money you're paying participants, it's a super deep dive. Right. And if you test a product on ten people, that's ten out. When I was at Microsoft, I don't know if they still do it this way, but at Microsoft, they did it in person. So the person comes to the campus, it's like 100 $200 per person. You spend an hour with them going over design. So that's 10 hours of research time, plus it's going to take at least double that to analyze it. Like, it's just a really large undertaking. So you want to have put serious thought into what it is that you're testing, but it's not always at that point. Like, this is just if you're developing a specific feature, sometimes qualitative researches will be brought in earlier when it's like, we think there's a problem here or we're curious to know some more insights or whatever, and there you would have you can have more generating generous qualitative research."
93;Speaker 1;00:31:21.430;00:31:21.690;00:00:00.260;"Right."
94;Speaker 2;00:31:21.740;00:31:48.550;00:00:26.810;"For example, if we want to introduce a new paid subscription model or something, this is a very product facing product focused on. But you could have one where it's like, we're going to introduce some kind of paid model, and then that's less focused on UI and more focus on what people want in general. I see this is just like a very specific type of qualitative research."
95;Speaker 1;00:31:48.610;00:32:18.240;00:00:29.630;"I guess. I see it. Thank you for your answer. So I think after they conduct qualitative research, then the data is used to get consensus. Do you think the research achieved from the qualitative data is useful to get consensus on a lot of stakeholders in the team?"
96;Speaker 2;00:32:18.930;00:33:02.470;00:00:43.540;"Yeah, it's extremely useful because they spent so much time with it and they're able to go really deep on it, and it's the best indicator of how customers will perceive something that we have. So it's extremely useful. And this might be company specific, but I think the thing that was a little bit difficult for some UX researchers that I've known is the idea of being an informant but not a decision maker. You're providing insights based on what you've seen, and you've spent a lot of time working with people and with the data and with the prototype, but you're not actually the one that's making the decision. So that's why I put a red flag here."
97;Speaker 1;00:33:02.640;00:33:06.910;00:00:04.270;"I see. That usually makes decision."
98;Speaker 2;00:33:07.710;00:33:34.020;00:00:26.310;"It really depends on the team. Ours was product informed by costs, basically. So product managers are in charge of the roadmap, so they decide what gets built next. But you're dealing with a lot of constraints in terms of, like, how many engineers you have or what the money is that you have to spend and so that'll impact it."
99;Speaker 1;00:33:34.710;00:33:59.400;00:00:24.690;"I see. Okay, then let's talk about your experience of conducting qualitative analysis for user sentiment segmentation. Yeah. Can you explain your typical process of analyzing qualitative data when you're working on that project?"
100;Speaker 2;00:33:59.910;00:35:05.560;00:01:05.650;"Yeah, this one, I guess what I would do. So there's usually a note, take it. There was many different steps to it, but one of the ones that I think is most relevant was these interviews. And there is a note taker and there is an interviewer. And because I was on a design and a research team, everybody is really good at this, right. So even like, sometimes I could not do the full interview myself and somebody else could do it if I had the right. So I would go through each of the notes basically, and then fill them out. So notes are off the cuff. But usually I would replace like, here's the question that was asked and here's the insight and things like that. So that takes a really long time. And usually it's like split screen type of thing, right. Where you have notes on one side, you have the interview on the other side, and you're like running the interview at like double speed or something while you're filling out the notes."
101;Speaker 1;00:35:05.650;00:35:07.000;00:00:01.350;"Yes, I see."
102;Speaker 2;00:35:08.290;00:36:11.280;00:01:02.990;"And then I would either do like a thematic analysis or I might start tagging things that jump out to me as being like part of one particular theme. And then once I have a few of those, I'll group them by theme and see how many people that applies to. And then once I have that, I would actually chat with other members of the team. So I'll say, here's the theme that I think I'm seeing. Do you have any context to this? What do you think? How would you think about it just to get other voices involved? I see the analysis and then if I want to, like, you often do this as you go. So you might add more questions to the interview protocol or you might decide, I'm going to do three more interviews because I have this really interesting thing and I want to know more about it. So as you're doing the analysis, it might be changed, the interviewing that you're doing. And then finally you'll put it into like a presentation and present it to the people."
103;Speaker 1;00:36:14.110;00:36:35.380;00:00:21.270;"Okay. Then you said use some methods like tagging and asking opinions of your other collaborators. Do you think listening other researchers opinions help you to find more novel and new insights from qualitative data?"
104;Speaker 2;00:36:35.710;00:36:36.460;00:00:00.750;"Yeah."
105;Speaker 1;00:36:38.230;00:36:43.850;00:00:05.620;"Is there any case that you have to conduct by yourself without any collaborator?"
106;Speaker 2;00:36:47.270;00:37:00.870;00:00:13.600;"I mean, it'll happen that you have a project that is more or less self driven, but you always have a team, right. So if you need an opinion, even if you're working on something by yourself, there's always someone that you can go to."
107;Speaker 1;00:37:00.980;00:37:01.820;00:00:00.840;"I see."
108;Speaker 2;00:37:04.710;00:37:30.660;00:00:25.950;"Okay. And usually another thing that I'll say is usually these products, projects don't come up out of nowhere. Right. Like, as a UX researcher, it's very rare that you're just like what UX research do I want to do. And usually it's somebody else saying, here's the UX research that we want to see. So that means that there's almost always somebody that you're in touch with because there's somebody that cares about the outcome of what you're doing."
109;Speaker 1;00:37:30.800;00:37:37.870;00:00:07.070;"I see. Then why do you think listening to other people's opinion helps you to find new insights?"
110;Speaker 2;00:37:39.270;00:38:00.550;00:00:21.280;"I mean, it might just have to do with my working style, but I feel like I generate opinions from talking to other people and not by myself. You can get going and you have the same ideas over and over again. And also people have different like other people that have done interviews on other people that will make them recall something else. And so it's just like everybody has a slightly different perspective."
111;Speaker 1;00:38:01.830;00:38:17.290;00:00:15.460;"I see. Okay, then do you think there are differences between conducting qualitative data analysis in academia for research purposes and in the industry for product development purposes?"
112;Speaker 2;00:38:18.030;00:38:22.260;00:00:04.230;"Yeah, huge differences. I mean, the IRB is a really big one, right?"
113;Speaker 1;00:38:23.190;00:38:24.240;00:00:01.050;"That's true."
114;Speaker 2;00:38:25.410;00:38:57.700;00:00:32.290;"Irb is a huge difference. The other thing is, in industry, the outcome is much less precise. So really, it usually comes down to, yeah, you have to make a good slide deck and a good presentation, but it comes down to that presentation and how much you're able to convince people of something or just like create a good presentation, whereas in academia you have to document everything and really set your sources and relevant work. And it's just a much more detailed process. But that also means that industry can move a lot faster."
115;Speaker 1;00:38:57.730;00:39:10.970;00:00:13.240;"Right. And you can. Right. Then why do you think qualitative research is important to develop a product in the industry?"
116;Speaker 2;00:39:13.670;00:39:30.140;00:00:16.470;"I think there's a lot of things that are done from afar in industry in terms of analyzing data and building products, and you get pretty far removed, but you get really rich insight from qualitative data analysis, and there's very few things that be talking to people."
117;Speaker 1;00:39:30.710;00:39:43.710;00:00:13.000;"I see. Okay. Then why do you think it is difficult to conduct qualitative research in the industry and apply insights into the product development?"
118;Speaker 2;00:39:51.870;00:39:56.290;00:00:04.420;"I don't think it's that just like that's what UX researchers are for."
119;Speaker 1;00:39:56.340;00:39:57.900;00:00:01.560;"Right, right."
120;Speaker 2;00:39:58.950;00:40:06.780;00:00:07.830;"There's pain points, but I don't think it's like integrating UX research into the development process is difficult."
121;Speaker 1;00:40:07.290;00:40:16.620;00:00:09.330;"I see. Okay, then did you find any challenges while you're conducting qualitative data analysis for your project?"
122;Speaker 2;00:40:19.450;00:41:09.870;00:00:50.420;"Well, I think one of them is it just takes a lot of time to parse through. And like, if you want to add one more theme, you have to go through everything again from the very beginning, which is really difficult. I also think you need to be judicious about involving other people. And for me, like I said, I generate a lot of good ideas when I'm talking to other people, so I need to make sure I'm able to involve them. And sometimes it's harder and sometimes it's easier. I think the biggest one, like I pointed out, is that often you're not the decision maker. You're just telling people what you saw and what you observed, and it's kind of up to them to make the decision, which I think can be a little bit challenging."
123;Speaker 1;00:41:11.090;00:41:24.750;00:00:13.660;"I see. But as a US researcher, do you want to make decisions instead of just becoming an inside provider?"
124;Speaker 2;00:41:24.940;00:41:40.610;00:00:15.670;"Yeah, I think it can be very frustrating in a company to not be in a position to make decisions, especially if it's like, again, you've put so much time into it, you know, the subject matter, you're a subject matter expert to other people to decide."
125;Speaker 1;00:41:40.660;00:41:41.250;00:00:00.590;"I see."
126;Speaker 2;00:41:41.370;00:41:43.920;00:00:02.550;"Whether or not seriously, basically."
127;Speaker 1;00:41:44.120;00:42:02.150;00:00:18.030;"I see. But are there some cases that you actually researchers think certain problem is super important, but project managers don't take that seriously. So they just don't involve their insights into the product development?"
128;Speaker 2;00:42:03.310;00:42:04.300;00:00:00.990;"Yeah, definitely."
129;Speaker 1;00:42:05.230;00:42:45.630;00:00:40.400;"I see. Okay. But in that case, then benefit of qualitative data analysis is not fully accommodated into the whole process because you mentioned even though there are some pain points that US researchers feel. But you said it is not difficult to accommodate the insights they got from the data analysis into the product. So I thought their interests are well represented in the product development."
130;Speaker 2;00:42:46.310;00:42:52.700;00:00:06.390;"Yeah. I mean, I think on the whole they are, but I don't think they always are. Right. Just because they're pain points doesn't mean it's not happening."
131;Speaker 1;00:42:53.270;00:43:15.670;00:00:22.400;"I see. Okay, then I will go to the finer section of this interview. If you can have any type of support for finding insights from qualitative data, what support would you want to receive?"
132;Speaker 2;00:43:21.310;00:44:10.150;00:00:48.840;"Okay, which major translation is a huge one. I mean, I used that or transcription. The better that is, the better it is. That's like the biggest time sync. I would say other things are like tools that make it really easy to tag and collaborate with other people are really helpful. I've already used a tool called Max QDA the most. But that tool makes it a bit difficult to collaborate with other people. So cross collaboration would be really nice. I think another huge thing is a lot of qualitative data is retrieved on a one time basis. Like there's like one project and you have to do something for that one project and then you move on. But those interviews, we should just be using those."
133;Speaker 1;00:44:10.190;00:44:10.360;00:00:00.170;"Right."
134;Speaker 2;00:44:10.380;00:44:19.840;00:00:09.460;"Like, you should be building a bank of interviews that are easy to search instead of just like repeating new data analysis each time."
135;Speaker 1;00:44:20.410;00:44:30.040;00:00:09.630;"I see. Yeah. Actually, my other participant mentioned that they were building like a bank of interviews. Yeah."
136;Speaker 2;00:44:31.270;00:44:37.000;00:00:05.730;"I mean, just because you're going off the different problems, like there's still valuable data, right?"
137;Speaker 1;00:44:38.890;00:44:52.070;00:00:13.180;"Okay. Then if there is a human assistance, how would you like them to help you maximize the efficiency of finding insights from qualitative data and improve the quality of insights?"
138;Speaker 2;00:44:53.530;00:44:56.560;00:00:03.030;"Transcription and tagging are the two things I don't like."
139;Speaker 1;00:44:59.570;00:45:15.440;00:00:15.870;"Okay. And if you can use AI in your work to improve the quality and quantity of insights derived from qualitative data, what do you expect AI to do to help you?"
140;Speaker 2;00:45:16.670;00:45:18.810;00:00:02.140;"Still transcription and tag."
141;Speaker 1;00:45:24.450;00:45:26.110;00:00:01.660;"Really time consuming."
142;Speaker 2;00:45:26.910;00:45:30.090;00:00:03.180;"I think AI and people can do this actually."
143;Speaker 1;00:45:30.130;00:45:30.550;00:00:00.420;"Okay."
144;Speaker 2;00:45:30.660;00:46:25.190;00:00:54.530;"I take it back now when I hear them. So obviously transcription, tagging are the ones that I don't like. And so if I can get something else, whether it's human or Ice, do that for me, that'd be fantastic. But one thing I do like doing with humans is we both read two of the same interviews or something and then we talk to each other about what the main themes are or something and that generating insights together I think is helpful. I think machines and AI transcription is an obvious one. Also pulling out. Like I've also used Otter AI and they'll pull out sometimes relevant words that they find or some things that they think have come up a lot in terms of where to direct your attention to as a human, I think that is helpful."
145;Speaker 1;00:46:28.150;00:46:38.740;00:00:10.590;"Are you using those features when you're conducting your own work? Like pulling up some important words so it guides you where you should look at?"
146;Speaker 2;00:46:40.990;00:46:46.250;00:00:05.260;"I think I look at them, but right now they're not really good enough for it to be that helpful."
147;Speaker 1;00:46:46.630;00:46:48.530;00:00:01.900;"Why do you think it's not helpful?"
148;Speaker 2;00:46:50.350;00:47:14.030;00:00:23.680;"Because it's just one word. Right. So I'm like, okay, Facebook came up three times in this interview. Like I don't care. But if it's something like Facebook plus like sentiment analysis or something like that, or it's like weaving a thread or able to pull up all of the relevant or even if I can type in a word that I'm curious about and it gets the things that are most similar, like all of those things can be really useful."
149;Speaker 1;00:47:14.350;00:47:31.900;00:00:17.550;"I see if AI can summarize the whole interview transcript and provide some using topic modeling, do you think those type of reports can be useful for you to find insights from the data?"
150;Speaker 2;00:47:35.870;00:48:32.870;00:00:57.000;"I think summarization, yes, because that's what I was saying earlier. Right. Like you have to go through the interview at two X speed and type up like that's basically what you're doing. Right. At that point. So summarization could be really useful. I would be worried that it's like missing things that I think are important, that the algorithm might not think is important. And then in terms of tagging or topic modeling, I think it could be helpful. But again, in the example that I just mentioned, I've had something that's able to pull out just like specific words and that's not super helpful. So I think it needs to be a little more contextual about. Like, here are some things that I'm looking for, and I think more of like guiding attention so that I can go through it and then extract the things that I think are important. I think that maybe is more relevant."
151;Speaker 1;00:48:34.690;00:48:47.090;00:00:12.400;"You said there are some limitations of AI suggestions, but do you think if you add human input into that AI suggestion, then do you think it can be improved?"
152;Speaker 2;00:48:48.730;00:49:07.660;00:00:18.930;"I mean, it depends on how well the human is. Right. If it's a random human, maybe in some cases it helps others it doesn't. If it's like somebody else that is well trained and that knows the question that we're going off to like, yeah, that helpful. But then at that point you don't really need the AI as much."
153;Speaker 1;00:49:15.770;00:49:26.160;00:00:10.390;"Okay. So I think this is the end of the interview. Cool. Thanks again for participating. I really appreciate it."
154;Speaker 2;00:49:26.670;00:49:29.110;00:00:02.440;"Yeah, of course. I hope it was helpful."
155;Speaker 1;00:49:30.450;00:49:38.090;00:00:07.640;"It was super helpful. Do you have any feedback how I can improve this interview?"
156;Speaker 2;00:49:40.150;00:50:24.260;00:00:44.110;"Well, I get some feedback on the form. I think one thing, it would be helpful at the beginning to be told what you're going to ask about. So be told, like there's going to be first form, then I'm going to ask questions. I'm trying to think the other thing, which I always do this too. But you are asking a couple of leading questions which you may want to try to stay away from, but otherwise no, I think it was good."
157;Speaker 1;00:50:24.830;00:50:25.590;00:00:00.760;"Thank you."
158;Speaker 2;00:50:25.700;00:50:26.010;00:00:00.310;"Yeah."
159;Speaker 1;00:50:26.060;00:50:27.150;00:00:01.090;"Thank you so much."
160;Speaker 2;00:50:27.320;00:51:05.900;00:00:38.580;"Yeah. And I'm trying to think in terms of. Yeah, I think also you may want to maybe, I don't know. I guess it's interesting because the questions you were asking and the tasks you have are very like, product oriented. But in my experience, it's not always oriented. Often it's oriented around product or feature for one and for two, it's not always oriented around production. It's not always oriented around development. And so maybe I wonder if it's like at the beginning getting some insight about what their process looks like or getting talk through it so that then you can adapt following tasks to what I see."
161;Speaker 1;00:51:06.530;00:51:30.260;00:00:23.730;"Well, I chose like, product development because, well, I kind of want to apply AI to solve problems for UX researchers. But I thought the researchers working for product development, they really don't have much time to spend on qualitative data analysis. So I thought they had more needs of AI, like support."
162;Speaker 2;00:51:32.870;00:51:55.610;00:00:22.740;"Yeah. I mean, that makes sense. But I think actually what you'll find is in industry, it's not always like you're not a UX researcher that works on product development. Like maybe half of the things that you do offer product development and half of the things you do are like for marketing or for the business unit or something. So not always baked into the product process."
163;Speaker 1;00:51:55.710;00:51:58.100;00:00:02.390;"I see yeah."
164;Speaker 2;00:51:58.670;00:52:00.530;00:00:01.860;"But it's okay to scope it to this product."
165;Speaker 1;00:52:00.570;00:52:00.810;00:00:00.240;"Also."
166;Speaker 2;00:52:00.860;00:52:01.880;00:00:01.020;"If that's the one."
167;Speaker 1;00:52:04.610;00:52:06.800;00:00:02.190;"Thanks so much. Cool."
168;Speaker 2;00:52:06.880;00:52:10.090;00:00:03.210;"Alright. Good luck. Let me know if you need anything else."
169;Speaker 1;00:52:10.270;00:52:12.800;00:00:02.530;"Okay? Thank you. Have a good day."
170;Speaker 2;00:52:12.940;00:52:14.240;00:00:01.300;"Thank you. Bye."
